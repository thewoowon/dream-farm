"use client";

import PulseCircle from "@/components/element/pulse/Pulse";
import React, { useEffect, useRef, useState } from "react";
import customAxios from "@/lib/axios";
import { useMutation } from "@tanstack/react-query";
import { useRouter } from "next/navigation";
import useHeaderStore from "@/store/useHeaderStore";
import styled from "@emotion/styled";
import { DotLottieReact } from "@lottiefiles/dotlottie-react";
// ë¡œë  íƒ€ì… ë¶ˆëŸ¬ì˜¤ê¸°
import { DotLottieReactProps } from "@lottiefiles/dotlottie-react";

type SpeechRecognitionStatus =
  | "onstart"
  | "onspeechstart"
  | "onspeechend"
  | "error"
  | "onend";

const VoicePage = () => {
  const [text, setText] = useState("ğŸ¤ ë§ˆì´í¬ë¥¼ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”!");

  const [status, setStatus] = useState<SpeechRecognitionStatus>("onend");
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const [shouldPulse, setShouldPulse] = useState(false);
  const [scale, setScale] = useState<number[]>([1, 1.1, 1]);
  const [communicationContext, setCommunicationContext] = useState<
    {
      content: string;
      role: "user" | "assistant";
    }[]
  >([]);
  const [loading, setLoading] = useState(false);

  const router = useRouter();
  const { change } = useHeaderStore();

  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  const [lottie, setLottie] = useState<any>(null);

  const { mutate: sendMessage } = useMutation({
    mutationFn: async (message: string) => {
      try {
        const response = await customAxios.post(
          "/chat/chatToAudio",
          {
            text: message,
            userId: "5d8d0894-f643-495d-8a41-273dc25126d3", // ì‚¬ìš©ì IDë¥¼ í•˜ë“œì½”ë”©
          },
          {
            headers: {
              "Content-Type": "application/json",
            },
            responseType: "json", // ê·¸ëŒ€ë¡œ ë‘¬ë„ ë¨
            withCredentials: true,
          }
        );

        return response.data;
      } catch (error) {
        console.error("ì˜¤ë””ì˜¤ ìš”ì²­ ì‹¤íŒ¨:", error);
        throw error;
      }
    },
    onSuccess: (data) => {
      const audioData = data as {
        text: string;
        audio: string; // base64 ë¬¸ìì—´
      };

      // base64ë¥¼ Blobìœ¼ë¡œ ë³€í™˜
      const byteString = atob(
        audioData.audio.replace(/^data:audio\/mpeg;base64,/, "")
      );
      const byteArray = new Uint8Array(byteString.length);
      for (let i = 0; i < byteString.length; i++) {
        byteArray[i] = byteString.charCodeAt(i);
      }
      const blob = new Blob([byteArray], { type: "audio/mpeg" });

      const audioUrl = URL.createObjectURL(blob);
      const audio = new Audio(audioUrl);
      audio.play();

      console.log("ì˜¤ë””ì˜¤ ì¬ìƒ:", audioData.text);
      setCommunicationContext((prev) => [
        ...prev,
        { content: audioData.text, role: "assistant" },
      ]);
      audio.onended = () => {
        setLoading(false); // ì˜¤ë””ì˜¤ ì¬ìƒì´ ëë‚˜ë©´ ë¡œë”© ìƒíƒœ í•´ì œ
        setText("ğŸ¤ ë§ˆì´í¬ë¥¼ ëˆŒëŸ¬ ë§í•´ë³´ì„¸ìš”!");
      }; // ì˜¤ë””ì˜¤ ì¬ìƒì´ ëë‚˜ë©´ ë¡œë”© ìƒíƒœ í•´ì œ
      setText(`ğŸ¤– "${audioData.text}"`);
    },
    onError: (error) => {
      console.error("ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨:", error);
      setText("âŒ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨");
    },
  });

  const startListening = () => {
    if (!recognitionRef.current) return;

    try {
      recognitionRef.current.start();
      setStatus("onstart");
      setText("ğŸ§ ë“£ëŠ” ì¤‘ì…ë‹ˆë‹¤. ë§í•´ë³´ì„¸ìš”!");
    } catch (err) {
      console.error("ì¸ì‹ ì‹œì‘ ì‹¤íŒ¨:", err);
    }
  };

  useEffect(() => {
    if (typeof window === "undefined") return;

    const SpeechRecognition =
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      window.SpeechRecognition || (window as any).webkitSpeechRecognition;

    if (!SpeechRecognition) {
      alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = "ko-KR";
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;
    recognition.continuous = false;

    recognition.onstart = () => {
      // setStatus("ğŸŸ¢ ì¸ì‹ ì‹œì‘ë¨");
      setStatus("onstart");
      setShouldPulse(true);
    };

    recognition.onspeechstart = () => {
      // setStatus("ğŸ—£ï¸ ë§í•˜ëŠ” ì¤‘...");
      setStatus("onspeechstart");
      setShouldPulse(true);
      setScale([1, 1.3, 1]); // ë§í•˜ëŠ” ì¤‘ì¼ ë•Œ í¬ê¸° ì¦ê°€
    };

    recognition.onspeechend = () => {
      // setStatus("ğŸ¤« ë§ ë©ˆì¶¤, ì¸ì‹ ì¤‘...");
      setStatus("onspeechend");
      setShouldPulse(false);
      setScale([1, 1.1, 1]); // ë§ ë©ˆì¶”ë©´ í¬ê¸° ì›ë˜ëŒ€ë¡œ
      recognition.stop(); // ìë™ìœ¼ë¡œ ì¸ì‹ ì¢…ë£Œ
    };

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      // setStatus("âœ… ì¸ì‹ ê²°ê³¼ ìˆ˜ì‹ ë¨");
      const transcript = event.results[0][0].transcript;
      const confidence = event.results[0][0].confidence;
      setText(`ğŸ“ "${transcript}" (ì •í™•ë„: ${(confidence * 100).toFixed(1)}%)`);

      setCommunicationContext((prev) => [
        ...prev,
        { content: transcript, role: "user" },
      ]);
      setLoading(true); // ë¡œë”© ìƒíƒœë¡œ ë³€ê²½
      sendMessage(transcript); // ë©”ì‹œì§€ ì „ì†¡
      recognition.stop(); // ì¸ì‹ ì¢…ë£Œ
    };

    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    recognition.onerror = (event: any) => {
      setText(`âŒ ì˜¤ë¥˜: ${event.error}`);
      // setStatus("ğŸ”´ ì˜¤ë¥˜ ë°œìƒ");
      setStatus("error");
      setShouldPulse(false);
      setScale([1, 1.1, 1]); // ë§ ë©ˆì¶”ë©´ í¬ê¸° ì›ë˜ëŒ€ë¡œ
    };

    recognition.onend = () => {
      // setStatus("ğŸ”µ ì¸ì‹ ì¢…ë£Œë¨");
      setStatus("onend");
      setShouldPulse(false);
      setScale([1, 1.1, 1]); // ë§ ë©ˆì¶”ë©´ í¬ê¸° ì›ë˜ëŒ€ë¡œ
    };

    recognitionRef.current = recognition;
  }, [sendMessage]);

  useEffect(() => {
    if (shouldPulse) {
      if (lottie) {
        lottie.play();
      }
    } else {
      lottie?.stop();
    }
  }, [lottie, shouldPulse]);

  return (
    <Main>
      <div
        style={{
          width: "100%",
          height: "57px",
          display: "flex",
          justifyContent: "space-between",
          alignItems: "center",
          fontSize: "16px",
          fontWeight: 600,
          lineHeight: "24px",
          letterSpacing: "-2%",
          color: "#000000",
          minHeight: "57px",
        }}
      >
        <svg
          onClick={() => {
            router.push("/ai/read?id=1");
            change("block");
          }}
          width="24"
          height="25"
          viewBox="0 0 24 25"
          fill="none"
          xmlns="http://www.w3.org/2000/svg"
        >
          <path
            d="M14.998 19.5L7.99805 12.5L14.998 5.5"
            stroke="#1E1E1E"
            strokeWidth="1.5"
            strokeLinecap="round"
            strokeLinejoin="round"
          />
        </svg>
        AI ë“œë¦¬ë¯¸
        <div></div>
      </div>
      {/* <p>{text}</p> */}
      {/* <p style={{ marginTop: "1rem", fontWeight: "bold" }}>{status}</p> */}
      <div
        style={{
          display: "flex",
          flexDirection: "column",
          alignItems: "center",
          justifyContent: "center",
          textAlign: "center",
          fontSize: "20px",
          fontWeight: 600,
          lineHeight: "28px",
          letterSpacing: "-2%",
          color: "#000000",
          marginTop: "56px",
        }}
      >
        â€œì•ˆë…•í•˜ì„¸ìš”. <br />
        ì €ëŠ” AI ê·€ë† ìƒë‹´ì‚¬ ë“œë¦¬ë¯¸ì—ìš”.
        <br />
        ê¶ê¸ˆí•˜ì‹ ê±¸ í¸í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš”.â€
      </div>
      <DotLottieReact
        src="/assets/dreami.lottie"
        loop={true}
        autoplay={false}
        style={{
          width: "100%",
          maxWidth: "400px",
          height: "auto",
        }}
        dotLottieRefCallback={(instance) => {
          setLottie(instance);
        }}
      />
      {/* <PulseCircle shouldPulse={shouldPulse} scale={scale} /> */}
      {(status == "onstart" || status == "onspeechstart") && (
        <div>ë“£ê³  ìˆì–´ìš”..</div>
      )}
      <div
        style={{
          marginTop: "1rem",
          display: "flex",
          justifyContent: "center",
          alignItems: "center",
        }}
      >
        <button
          disabled={loading}
          onClick={startListening}
          style={{
            padding: "0.75rem 1.5rem",
            fontSize: "1rem",
            borderRadius: "8px",
            backgroundColor: loading ? "#888" : "#000000",
            color: "white",
            border: "none",
          }}
        >
          ì—¬ê¸°ë¥¼ ëˆ„ë¥´ê³  ë§í•´ì£¼ì„¸ìš”.
        </button>
        {/* <button
          onClick={stopListening}
          style={{
            padding: "0.75rem 1.5rem",
            fontSize: "1rem",
            borderRadius: "8px",
            background: "#888",
            color: "white",
            border: "none",
          }}
        >
          â¹ï¸ ì¸ì‹ ì¤‘ì§€
        </button> */}
      </div>
    </Main>
  );
};

export default VoicePage;

const Main = styled.main`
  width: 100%;
  display: flex;
  height: calc(var(--vh, 1vh) * 100);
  flex-direction: column;
  align-items: center;
  justify-content: flex-start;
  padding: 0px 16px 20px 16px;

  overflow-x: hidden;
  overflow-y: auto;

  &::-webkit-scrollbar {
    display: none;
  }
  scrollbar-width: none;
  --ms-overflow-style: none;
  position: relative;
`;
